{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2480bb10-3eae-424d-9255-276aac945d7e",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "This file is the starting point of the project. Here, we aim to upload the partially cleaned files to a AWS bucket.\n",
    "\n",
    "To start, the raw files were downloaded from the [National Library of Medicine](https://lhncbc.nlm.nih.gov/ii/tools/SemRep_SemMedDB_SKR/SemMedDB_download.html). Since these are some pretty large files (up to 16GB compressed) and they're officially available for download through the National Library of Medicine, these files are not uploaded with the code. The folders in which they were stored and referenced have been kept if you would like to re-run the code on your own.\n",
    "\n",
    "This project was completed using the SEMMED v43, 2023, Regular version of these files.\n",
    "\n",
    "Now, some manual cleaning was required before starting running any Python Code. As any Data Scientist/Analyst knows, many data processing packages like Pandas and Dask can read data in multiple formats, however, certain characters can trip them up. Of these manual changes (which took quite some time), the most important are:\n",
    " - Removing special characters like '\\\\'. These characters were littered across the files and caused a variety of issues when interpreted.\n",
    " - Removed some diacritics and accent marks from certain characters. ISO-8859-1 encoding parses some of these correctly and some like 'Ã–' incorrectly . Only the problematic ones were removed. \n",
    "\n",
    "Lastly, some important notes:\n",
    "- No official data encoding for the data was provided. ISO-8859-1 is the best match. This was found through visual inspection and manually testing different encodings.\n",
    "- The Database data doesn't seem to enforce any particular convention. For example, in some entries, a researcher's name will have the appropriate diacritics or accents added to characters. In other entries referencing the same researcher, their name will not contain any diacritics or accents. These differences should be noted and resolved if entries are used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8c512-5ef8-487d-8f8c-15c7b30bc7cf",
   "metadata": {},
   "source": [
    "## Python info\n",
    "\n",
    "While running `pip install -r requirements.txt` should suffice, all of the necessary packages can be installed by running `pip install` with the following packages:\n",
    " - boto3\n",
    " - dask[\"distributed\"]\n",
    " - jupyter\n",
    " - neo4j\n",
    " - numpy\n",
    " - pandas\n",
    " - progressbar\n",
    " - pyarrow\n",
    "\n",
    "Either way, here are the exact packages and versions installed in my Python Virtual Environment. Note the version of Python running as some versions of packages are only restricted to some versions of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e21797-0a8c-4e5c-8533-7dc6e7ac37cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version:\n",
      "Python 3.12.4\n",
      "\n",
      "Installed Packages w/ Versions:\n",
      "anyio==4.6.0\n",
      "appnope==0.1.4\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "async-lru==2.0.4\n",
      "attrs==24.2.0\n",
      "babel==2.16.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==6.1.0\n",
      "boto3==1.35.34\n",
      "botocore==1.35.34\n",
      "certifi==2024.8.30\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.3.2\n",
      "click==8.1.7\n",
      "cloudpickle==3.0.0\n",
      "comm==0.2.2\n",
      "dask==2024.9.1\n",
      "debugpy==1.8.6\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "distributed==2024.9.1\n",
      "executing==2.1.0\n",
      "fastjsonschema==2.20.0\n",
      "fqdn==1.5.1\n",
      "fsspec==2024.9.0\n",
      "h11==0.14.0\n",
      "httpcore==1.0.6\n",
      "httpx==0.27.2\n",
      "idna==3.10\n",
      "ipykernel==6.29.5\n",
      "ipython==8.28.0\n",
      "ipywidgets==8.1.5\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "jmespath==1.0.1\n",
      "json5==0.9.25\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter==1.1.1\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.10.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.14.2\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.2.5\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.3\n",
      "jupyterlab_widgets==3.0.13\n",
      "locket==1.0.0\n",
      "MarkupSafe==2.1.5\n",
      "matplotlib-inline==0.1.7\n",
      "mistune==3.0.2\n",
      "msgpack==1.1.0\n",
      "nbclient==0.10.0\n",
      "nbconvert==7.16.4\n",
      "nbformat==5.10.4\n",
      "neo4j==5.25.0\n",
      "nest-asyncio==1.6.0\n",
      "notebook==7.2.2\n",
      "notebook_shim==0.2.4\n",
      "numpy==2.1.1\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pandas==2.2.3\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "partd==1.4.2\n",
      "pexpect==4.9.0\n",
      "platformdirs==4.3.6\n",
      "progressbar==2.5\n",
      "prometheus_client==0.21.0\n",
      "prompt_toolkit==3.0.48\n",
      "psutil==6.0.0\n",
      "ptyprocess==0.7.0\n",
      "pure_eval==0.2.3\n",
      "pyarrow==17.0.0\n",
      "pycparser==2.22\n",
      "Pygments==2.18.0\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.0.1\n",
      "python-json-logger==2.0.7\n",
      "pytz==2024.2\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.2.0\n",
      "referencing==0.35.1\n",
      "requests==2.32.3\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rpds-py==0.20.0\n",
      "s3transfer==0.10.2\n",
      "Send2Trash==1.8.3\n",
      "setuptools==75.1.0\n",
      "six==1.16.0\n",
      "sniffio==1.3.1\n",
      "sortedcontainers==2.4.0\n",
      "soupsieve==2.6\n",
      "stack-data==0.6.3\n",
      "tblib==3.0.0\n",
      "terminado==0.18.1\n",
      "tinycss2==1.3.0\n",
      "toolz==1.0.0\n",
      "tornado==6.4.1\n",
      "traitlets==5.14.3\n",
      "types-python-dateutil==2.9.0.20241003\n",
      "tzdata==2024.2\n",
      "uri-template==1.3.0\n",
      "urllib3==2.2.3\n",
      "wcwidth==0.2.13\n",
      "webcolors==24.8.0\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "widgetsnbextension==4.0.13\n",
      "zict==3.0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Python Version:\")\n",
    "!python --version\n",
    "\n",
    "print(\"\\nInstalled Packages w/ Versions:\")\n",
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38713cf-6806-4cbe-941d-555d2f14db32",
   "metadata": {},
   "source": [
    "## Important globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ff563",
   "metadata": {},
   "source": [
    "### Changes to Official Site\n",
    "\n",
    "The next section details some pretty important discrepancies between the data and documentation available of the National Library of Medicine's site.\n",
    "\n",
    "After finding these discrepancies, I reported them using the through a general \"Contact Us\" inquiry. Little did I know, one of the lead developers/maintainers of the site would contact me back. Through our email chain, I described the various oddities and received confirmations of them.\n",
    "\n",
    "The maintainers agreed to update their documentation with the updated details produced from the inquiry; a highlight of my year for sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404130da-55db-492b-818b-17571178d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "root = os.path.join(Path.cwd(), \"..\", \"csv\")\n",
    "\n",
    "# Uncompressed files - Used for inspection.\n",
    "ENTITY_FILE = os.path.join(root, \"semmedVER43_2023_R_ENTITY.csv\")\n",
    "PREDICATION_FILE = os.path.join(root, \"semmedVER43_2023_R_PREDICATION.csv\")\n",
    "SENTENCE_FILE = os.path.join(root, \"semmedVER43_2023_R_SENTENCE.csv\")\n",
    "\n",
    "# Pre-compressed files\n",
    "zipped = os.path.join(root, \"zipped\")\n",
    "ENTITY_ZIP = os.path.join(zipped, \"semmedVER43_2023_R_ENTITY.csv.gz\")\n",
    "PREDICATION_ZIP = os.path.join(zipped, \"semmedVER43_2023_R_PREDICATION.csv.gz\")\n",
    "SENTENCE_ZIP = os.path.join(zipped, \"semmedVER43_2023_R_SENTENCE.csv.gz\")\n",
    "\n",
    "# Column labels for indexing. Found in schema desc(https://lhncbc.nlm.nih.gov/ii/tools/SemRep_SemMedDB_SKR/dbinfo.html)\n",
    "PREDICATION_COLUMNS = {\n",
    "    \"PREDICATION_ID\": str,  # Auto-generated primary key for each unique predication\n",
    "    \"SENTENCE_ID\": str,     # Foreign key to the SENTENCE table\n",
    "    \"PMID\": str,            # The PubMed identifier of the citation to which the predication belongs\n",
    "    \"PREDICATE\": str,       # The string representation of each predicate (for example TREATS, PROCESS_OF)\n",
    "    \"SUBJECT_CUI\": str,     # The CUI of the subject of the predication\n",
    "    \"SUBJECT_NAME\": str,    # The preferred name of the subject of the predication\n",
    "    \"SUBJECT_SEMTYPE\": str, # The semantic type of the subject of the predication\n",
    "    \"SUBJECT_NOVELTY\": str, # The novelty of the subject of the predication\n",
    "    \"OBJECT_CUI\": str,      # The CUI of the object of the predication\n",
    "    \"OBJECT_NAME\": str,     # The preferred name of the object of the predication\n",
    "    \"OBJECT_SEMTYPE\": str,  # The semantic type of the object of the predication\n",
    "    \"OBJECT_NOVELTY\": str,  # The novelty of the object of the predication\n",
    "}\n",
    "\n",
    "\n",
    "SENTENCE_COLUMNS= {\n",
    "    \"SENTENCE_ID\": str,               # Auto-generated primary key for each sentence\n",
    "    \"PMID\": str,                      # The PubMed identifier of the citation to which the sentence belongs\n",
    "    \"TYPE\": str,                      # 'ti' for the title of the citation, 'ab' for the abstract\n",
    "    \"NUMBER\": str,                    # The location of the sentence within the title or abstract\n",
    "    \"SENT_START_INDEX\": str,          # The character position within the text of the MEDLINE citation of the first character of the sentence  NEW\n",
    "    \"SENT_END_INDEX\": str,            # The character position within the text of the MEDLINE citation of the last character of the sentence  NEW\n",
    "    \"SECTION_HEADER\": str,            # Section header name of structured abstract (from Version 3.1)\n",
    "    \"NORMALIZED_SECTION_HEADER\": str, # Normalized section header name of structured abstract (from Version 3.1)\n",
    "    \"SENTENCE\": str,                  # The actual string or text of the sentence\n",
    "}\n",
    "\n",
    "ENTITY_COLUMNS = {\n",
    "    \"ENTITY_ID\": str,    # Auto-generated primary key for each unique entity\n",
    "    \"SENTENCE_ID\": str,  # The foreign key to SENTENCE table\n",
    "    \"CUI\": str,          # The CUI of the entity\n",
    "    \"NAME\": str,         # The preferred name of the entity\n",
    "    \"TYPE\": str,         # The semantic type of the entity\n",
    "    \"GENE_ID\": str,      # The EntrezGene ID of the entity\n",
    "    \"GENE_NAME\": str,    # The EntrezGene name of the entity\n",
    "    \"TEXT\": str,         # The text in the utterance that maps to the entity\n",
    "    \"START_INDEX\": str,  # The first character position (in document) of the text denoting the entity\n",
    "    \"END_INDEX\": str,    # The last character position (in document) of the text denoting the entity\n",
    "    \"SCORE\": str,        # The confidence score\n",
    "}\n",
    "\n",
    "# Found in downloads page (https://lhncbc.nlm.nih.gov/ii/tools/SemRep_SemMedDB_SKR/SemMedDB_download.html)\n",
    "# Note, Entity file is supposed to have 1,892,228,683 rows, however, a line count using `wc -l` results in 1,887,317,669 new line \n",
    "# chars (n-1 rows) being detected on the unmodified file. This is consistent with the data read in after cleaning.\n",
    "EXPECTED_ROWS = {\n",
    "    \"PREDICATION\": 126268045,\n",
    "    \"SENTENCE\":    253029872, \n",
    "    # \"ENTITY\":      1892228683, # official amount from linked website.\n",
    "    \"ENTITY\":      1887317669 + 1,   # found amount.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d9c87-90e6-413b-b742-4f695b38c270",
   "metadata": {},
   "source": [
    "## File Utils\n",
    "\n",
    "Over the next few sections, we'll be reading in the raw files to ensure that Dask is capable of properly parsing the minimally-cleaned files. Again, we're not really doing much \"cleaning\" here, rather verifying that the files we store in our AWS bucket can be properly used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4a8143-0c60-491f-be88-f4ccb07f4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "\n",
    "def read_csv(filename:str, col_labels:list[str]=None, types:dict=None) -> dd:\n",
    "    \"\"\" Reads in CSV file.\n",
    "\n",
    "    Args: \n",
    "        filename: the path to file to load.\n",
    "        col_labels: the expected labels for each column. Default None.\n",
    "        types: column labels and their accompanying types. Default None.\n",
    "    Returns:\n",
    "        A Dask Dataframe object with loaded data.\n",
    "    \"\"\"\n",
    "    def print_values(bad_line: list[str]):\n",
    "        for i,item in enumerate(bad_line):\n",
    "            print(f\"Item {i}: {item}\")\n",
    "            \n",
    "    opts = {\n",
    "        \"blocksize\":        50e6,         # 50 MB chunks\n",
    "        \"dtype\":            np.str_,      # treat everything as string for now\n",
    "        \"on_bad_lines\":     \"warn\",\n",
    "        \"encoding\":         \"iso-8859-1\",\n",
    "        \"na_values\":        [\"\"],         # representation of empty values\n",
    "        \n",
    "        # \"engine\":       \"python\",       # uncomment next two lines if debugging / cleaning data\n",
    "        # \"on_bad_lines\": print_values,   # warning, will be VERY slow.\n",
    "    }\n",
    "\n",
    "\n",
    "    # type checking.\n",
    "    if col_labels and type(col_labels) != list:\n",
    "        print(f\"Column labels not in proper format. Expected list, got {type(col_labels)}.\")\n",
    "        col_labels = None\n",
    "    elif col_labels:\n",
    "        opts[\"names\"] = col_labels\n",
    "    if types and type(types) != dict:\n",
    "        print(f\"Types are not in proper format. Expected dict, got {type(types)}.\")\n",
    "        types = None\n",
    "    elif types:\n",
    "        opts[\"dtype\"] = types\n",
    "\n",
    "    df = dd.read_csv(filename,**opts)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1424f1f-4e5c-4e6e-97a5-67ee5237b912",
   "metadata": {},
   "source": [
    "### Predications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47e2f56-bfd0-4b4a-becb-b8df7ebc50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    predications = read_csv(PREDICATION_FILE, list(PREDICATION_COLUMNS.keys()), PREDICATION_COLUMNS)\n",
    "except Exception as e:\n",
    "    print(f\"Something seriously messed up happened.\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00221088-92ef-44fb-9b9b-dddb4595ccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 160.24 s\n",
      "Lost Rows: 0, Percent lost: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDICATION_ID</th>\n",
       "      <th>SENTENCE_ID</th>\n",
       "      <th>PMID</th>\n",
       "      <th>PREDICATE</th>\n",
       "      <th>SUBJECT_CUI</th>\n",
       "      <th>SUBJECT_NAME</th>\n",
       "      <th>SUBJECT_SEMTYPE</th>\n",
       "      <th>SUBJECT_NOVELTY</th>\n",
       "      <th>OBJECT_CUI</th>\n",
       "      <th>OBJECT_NAME</th>\n",
       "      <th>OBJECT_SEMTYPE</th>\n",
       "      <th>OBJECT_NOVELTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10592604</td>\n",
       "      <td>16</td>\n",
       "      <td>16530475</td>\n",
       "      <td>PROCESS_OF</td>\n",
       "      <td>C0003725</td>\n",
       "      <td>Arboviruses</td>\n",
       "      <td>virs</td>\n",
       "      <td>1</td>\n",
       "      <td>C0999630</td>\n",
       "      <td>Lepus capensis</td>\n",
       "      <td>mamm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10592697</td>\n",
       "      <td>17</td>\n",
       "      <td>16530475</td>\n",
       "      <td>ISA</td>\n",
       "      <td>C0039258</td>\n",
       "      <td>Tahyna virus</td>\n",
       "      <td>virs</td>\n",
       "      <td>1</td>\n",
       "      <td>C0446169</td>\n",
       "      <td>California Group Viruses</td>\n",
       "      <td>virs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10592728</td>\n",
       "      <td>17</td>\n",
       "      <td>16530475</td>\n",
       "      <td>ISA</td>\n",
       "      <td>C0318627</td>\n",
       "      <td>Eyach virus</td>\n",
       "      <td>virs</td>\n",
       "      <td>1</td>\n",
       "      <td>C0206590</td>\n",
       "      <td>Coltivirus</td>\n",
       "      <td>virs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10592759</td>\n",
       "      <td>17</td>\n",
       "      <td>16530475</td>\n",
       "      <td>ISA</td>\n",
       "      <td>C0446169</td>\n",
       "      <td>California Group Viruses</td>\n",
       "      <td>virs</td>\n",
       "      <td>1</td>\n",
       "      <td>C0003725</td>\n",
       "      <td>Arboviruses</td>\n",
       "      <td>virs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10592832</td>\n",
       "      <td>18</td>\n",
       "      <td>16530475</td>\n",
       "      <td>PROCESS_OF</td>\n",
       "      <td>C0012634</td>\n",
       "      <td>Disease</td>\n",
       "      <td>dsyn</td>\n",
       "      <td>0</td>\n",
       "      <td>C0020114</td>\n",
       "      <td>Human</td>\n",
       "      <td>humn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PREDICATION_ID SENTENCE_ID      PMID   PREDICATE SUBJECT_CUI  \\\n",
       "0       10592604          16  16530475  PROCESS_OF    C0003725   \n",
       "1       10592697          17  16530475         ISA    C0039258   \n",
       "2       10592728          17  16530475         ISA    C0318627   \n",
       "3       10592759          17  16530475         ISA    C0446169   \n",
       "4       10592832          18  16530475  PROCESS_OF    C0012634   \n",
       "\n",
       "               SUBJECT_NAME SUBJECT_SEMTYPE SUBJECT_NOVELTY OBJECT_CUI  \\\n",
       "0               Arboviruses            virs               1   C0999630   \n",
       "1              Tahyna virus            virs               1   C0446169   \n",
       "2               Eyach virus            virs               1   C0206590   \n",
       "3  California Group Viruses            virs               1   C0003725   \n",
       "4                   Disease            dsyn               0   C0020114   \n",
       "\n",
       "                OBJECT_NAME OBJECT_SEMTYPE OBJECT_NOVELTY  \n",
       "0            Lepus capensis           mamm              1  \n",
       "1  California Group Viruses           virs              1  \n",
       "2                Coltivirus           virs              1  \n",
       "3               Arboviruses           virs              1  \n",
       "4                     Human           humn              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    total_rows = predications.map_partitions(len).compute().sum()\n",
    "\n",
    "print(f\"Lost Rows: {EXPECTED_ROWS['PREDICATION']-total_rows}, Percent lost: {round((1.00 - (total_rows/EXPECTED_ROWS['PREDICATION'])), 3)}\")\n",
    "\n",
    "predications.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a10e5-1adf-4935-923a-bbfd214c8568",
   "metadata": {},
   "source": [
    "### Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b91483-9ac0-4caa-ad49-65aff5923576",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sentences = read_csv(SENTENCE_FILE, list(SENTENCE_COLUMNS.keys()), SENTENCE_COLUMNS)\n",
    "except Exception as e:\n",
    "    print(f\"Something seriously messed up happened.\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3083a8bc-0b0b-4259-ba34-36d35c7fc850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 417.76 s\n",
      "Lost Rows: 0, Percent lost: 0.0\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    total_rows = sentences.map_partitions(len).compute().sum()\n",
    "\n",
    "print(f\"Lost Rows: {EXPECTED_ROWS['SENTENCE']-total_rows}, Percent lost: {round(1.00 - (total_rows/EXPECTED_ROWS['SENTENCE']), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf68f98-34d4-44fc-a312-b7160baff7f9",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76290284-cc45-49ae-9587-859e5510d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    entities = read_csv(ENTITY_FILE, list(ENTITY_COLUMNS.keys()), ENTITY_COLUMNS)\n",
    "except Exception as e:\n",
    "    print(f\"Something seriously messed up happened.\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85efd19-5278-4fcd-82ca-4bc8fc5cd908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 28m 53s\n",
      "Lost Rows: 0, Percent lost: 0.0\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    total_rows = entities.map_partitions(len).compute().sum()\n",
    "\n",
    "print(f\"Lost Rows: {EXPECTED_ROWS['ENTITY']-total_rows}, Percent lost: {round(1.00 - (total_rows/EXPECTED_ROWS['ENTITY']), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae25fcf-7388-4007-b795-419a72482edd",
   "metadata": {},
   "source": [
    "## Uploading to AWS\n",
    "\n",
    "Here, we use the \"Boto3\" module to bypass some of the complexity behind uploading to AWS. The secrets to our AWS console session were stored in a `.env` file in the same folder. For more information about the credentials used, please visit the [official boto3 documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html).\n",
    "\n",
    "We upload pre-zipped versions of the raw csv files as both CSV and Parquet files since the data is relatively large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b06e6e-964c-4131-be00-78de4c300a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import boto3\n",
    "import progressbar\n",
    "\n",
    "env_v = dotenv_values(\".env\")\n",
    "class Uploader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.storage_opts= { \n",
    "                \"aws_access_key_id\" : env_v[\"aws_access_key_id\"],\n",
    "                \"aws_secret_access_key\": env_v[\"aws_secret_access_key\"],\n",
    "                \"aws_session_token\": env_v[\"aws_session_token\"]}\n",
    "        \n",
    "        self.s3 = boto3.client('s3', **self.storage_opts)\n",
    "\n",
    "    def update_pb(self, size):\n",
    "        self.pg.update(self.pg.currval + size)\n",
    "\n",
    "    def upload_file(self, file):\n",
    "        self.pg = progressbar.progressbar.ProgressBar(\n",
    "            maxval=os.stat(file).st_size)\n",
    "        self.pg.start()\n",
    "\n",
    "        self.s3.upload_file(file, 'semdb-data', os.path.basename(file), Callback=self.update_pb)\n",
    "\n",
    "uploader = Uploader()\n",
    "\n",
    "\n",
    "storage_opts = {'key': env_v[\"aws_access_key_id\"],\n",
    "                'secret': env_v[\"aws_secret_access_key\"],\n",
    "                'token': env_v[\"aws_session_token\"]}\n",
    "\n",
    "parquet_base_url = 's3://semdb-data/parquet/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a643a-7459-4644-b55b-5eabac36445a",
   "metadata": {},
   "source": [
    "## CSV Uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ae459c-6942-40b9-8c02-ae371fedafe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |######################################################################## |\r"
     ]
    }
   ],
   "source": [
    "uploader.upload_file(PREDICATION_ZIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b015693e-0995-44bf-8433-bbe5dc8ca14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |######################################################################################################################################################### |\r"
     ]
    }
   ],
   "source": [
    "uploader.upload_file(SENTENCE_ZIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201f494-4bcb-4791-b862-36488af89cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader.upload_file(ENTITY_ZIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27be2d-525d-4998-971e-71ef91710126",
   "metadata": {},
   "source": [
    "## Parquet Uploads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc7f8da-29a7-421a-8eef-84060a034c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 48m 23s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    s3_url = parquet_base_url+'predication'\n",
    "    predications.to_parquet(s3_url, storage_options=storage_opts, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9df12f6b-914d-43c4-90ae-8f80955fd546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 3hr 1ms\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    s3_url = parquet_base_url+'sentence'\n",
    "    sentences.to_parquet(s3_url, storage_options=storage_opts, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c65bbda-b305-42f4-a408-877e234a27af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 5hr 57m\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    s3_url = parquet_base_url+'entity'\n",
    "    entities.to_parquet(s3_url, storage_options=storage_opts, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
